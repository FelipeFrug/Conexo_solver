{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fd019fd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Carregando BERT...\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import random\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import time\n",
    "\n",
    "\n",
    "# Inicializa navegador\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))\n",
    "driver.get(\"https://contexto.me/en/\")\n",
    "\n",
    "print(\"ðŸ”„ Carregando BERT...\")\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "model = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "model.eval()\n",
    "\n",
    "# Embeddings cache\n",
    "embeddings = {}\n",
    "memory = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5f7110a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Palavras genÃ©ricas para abrir sentidos semÃ¢nticos\n",
    "temas_exploratorios = [\n",
    "    \"object\", \"place\", \"person\", \"animal\", \"emotion\",\n",
    "    \"food\", \"vehicle\", \"technology\", \"family\", \"music\",\n",
    "    \"clothing\", \"plant\", \"profession\", \"color\"\n",
    "]\n",
    "# \"tool\"\n",
    "temas_usados = set()\n",
    "\n",
    "# FunÃ§Ã£o para obter embedding\n",
    "def get_embedding(word):\n",
    "    if word in embeddings:\n",
    "        return embeddings[word]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        inputs = tokenizer(word, return_tensors=\"pt\", truncation=True)\n",
    "        inputs = {k: v for k, v in inputs.items()}\n",
    "        outputs = model(**inputs)\n",
    "        emb = outputs.last_hidden_state.mean(dim=1).squeeze().numpy()\n",
    "        embeddings[word] = emb\n",
    "        return emb\n",
    "\n",
    "# Adiciona chute manual\n",
    "def adicionar_chute(palavra, score):\n",
    "    print(f\"Chute registrado: '{palavra}' com score {score}\")\n",
    "    memory[palavra] = score\n",
    "    get_embedding(palavra)\n",
    "\n",
    "# SugestÃ£o adaptativa\n",
    "def sugerir_proximo():\n",
    "    print(\"\\nðŸŽ¯ Gerando novas sugestÃµes...\")\n",
    "\n",
    "    if not memory:\n",
    "        sugestao = random.choice(temas_exploratorios)\n",
    "        temas_usados.add(sugestao)\n",
    "        print(f\"ðŸ§­ ComeÃ§ando exploraÃ§Ã£o: {sugestao}\")\n",
    "        return [sugestao]\n",
    "\n",
    "    # ClassificaÃ§Ã£o refinada por score\n",
    "    perfeitos = [(p, s) for p, s in memory.items() if s < 50]\n",
    "    otimos    = [(p, s) for p, s in memory.items() if 50 <= s < 200]\n",
    "    bons      = [(p, s) for p, s in memory.items() if 200 <= s < 300]\n",
    "    oks       = [(p, s) for p, s in memory.items() if 300 <= s < 500]\n",
    "    ruins     = [(p, s) for p, s in memory.items() if s >= 500]\n",
    "\n",
    "    todos_ruins = len(ruins) == len(memory)\n",
    "\n",
    "    if todos_ruins:\n",
    "        restantes = [t for t in temas_exploratorios if t not in temas_usados]\n",
    "        if restantes:\n",
    "            sugestao = random.choice(restantes)\n",
    "            temas_usados.add(sugestao)\n",
    "            print(f\"ðŸ” Todos os chutes estÃ£o ruins. Explorando novo tema: {sugestao}\")\n",
    "            return [sugestao]\n",
    "        else:\n",
    "            print(\"âš  Todos os temas exploratÃ³rios jÃ¡ foram usados. Chutando palavra genÃ©rica aleatÃ³ria.\")\n",
    "            return [random.choice([w for w in tokenizer.vocab.keys() if w.isalpha() and len(w) > 4 and w not in memory])]\n",
    "\n",
    "    # Refinamento inteligente com prioridade por nÃ­vel\n",
    "    base = []\n",
    "\n",
    "    if len(perfeitos) >= 1:\n",
    "        base = sorted(perfeitos, key=lambda x: x[1])  # usa todos\n",
    "        print(f\"ðŸ’¥ Refinando a partir de perfeitos ({len(base)}): {[p for p, _ in base]}\")\n",
    "    elif len(otimos) >= 1:\n",
    "        base = sorted(otimos, key=lambda x: x[1])\n",
    "        print(f\"ðŸŒŸ Refinando a partir de Ã³timos ({len(base)}): {[p for p, _ in base]}\")\n",
    "\n",
    "    elif len(bons) >= 1:\n",
    "        base = sorted(bons, key=lambda x: x[1])\n",
    "        print(f\"ðŸ‘Œ Refinando a partir de bons ({len(base)}): {[p for p, _ in base]}\")\n",
    "\n",
    "    elif len(oks) >= 1:\n",
    "        base = sorted(oks, key=lambda x: x[1])\n",
    "        print(f\"ðŸ™‚ Refinando a partir de oks ({len(base)}): {[p for p, _ in base]}\")\n",
    "    else:\n",
    "        base = sorted(memory.items(), key=lambda x: x[1])[:2]\n",
    "        print(f\"ðŸ¤” Refinando com os menos ruins: {[p for p, _ in base]}\")\n",
    "\n",
    "    # CÃ¡lculo do vetor mÃ©dio com pesos\n",
    "    vetores = np.array([get_embedding(p) for p, _ in base])\n",
    "    pesos = np.array([1 / (s + 1) for _, s in base])\n",
    "    pesos = pesos / pesos.sum()\n",
    "    vetor_medio = np.average(vetores, axis=0, weights=pesos)\n",
    "\n",
    "    # SeleÃ§Ã£o de candidatos\n",
    "    candidatos = [w for w in tokenizer.vocab.keys() if w.isalpha() and len(w) > 4 and w not in memory]\n",
    "    random.shuffle(candidatos)\n",
    "    candidatos = candidatos[:1000]\n",
    "\n",
    "    melhor_palavra = None\n",
    "    melhor_sim = -1\n",
    "    dic_sim = {}\n",
    "    for w in candidatos:\n",
    "        vec = get_embedding(w)\n",
    "        sim = cosine_similarity([vetor_medio], [vec])[0][0]\n",
    "        dic_sim[w] = sim\n",
    "\n",
    "    # Ordena o dic_sim pelo valor de similaridade (do maior para o menor)\n",
    "    dic_sim_ordenado = sorted(dic_sim.items(), key=lambda x: x[1], reverse=True)\n",
    "    palavras = dic_sim_ordenado[:10]  # pega as 10 melhores palavras\n",
    "    lista_palavras = [p[0] for p in palavras]\n",
    "    print(f\"âœ… PrÃ³xima sugestÃ£o: {melhor_palavra} (sim={melhor_sim:.4f})\")\n",
    "    return lista_palavras\n",
    "\n",
    "def enviar_chute_site(palavra):\n",
    "    print(f\"\\naaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa'{palavra}'\")\n",
    "    palavra = str(palavra)\n",
    "    # Preenche o campo\n",
    "    input_box = driver.find_element(By.CSS_SELECTOR, \"input.word\")\n",
    "    input_box.clear()\n",
    "    input_box.send_keys(palavra)\n",
    "    input_box.send_keys(Keys.ENTER)\n",
    "\n",
    "    # Aguarda resposta\n",
    "    time.sleep(1.5)\n",
    "\n",
    "    # Verifica se apareceu a mensagem de palavra repetida\n",
    "    try:\n",
    "        msg_box = driver.find_element(By.CSS_SELECTOR, \".message-text\")\n",
    "        if \"already guessed\" in msg_box.text:\n",
    "            print(f\"âš ï¸ Palavra jÃ¡ testada: {palavra}\")\n",
    "            return palavra, None  # Ignorar\n",
    "    except:\n",
    "        pass  # nenhuma mensagem = segue normal\n",
    "\n",
    "    # LÃª o chute mais recente\n",
    "    try:\n",
    "        resultado = driver.find_element(By.CSS_SELECTOR, \".row-wrapper.current .row\")\n",
    "        texto = resultado.text.strip()\n",
    "        palavra_retornada, score = texto.split()\n",
    "        return palavra_retornada.lower(), int(score)\n",
    "    except Exception as e:\n",
    "        print(\"âš ï¸ Erro ao tentar ler o resultado:\", e)\n",
    "        return palavra, None\n",
    "\n",
    "def reenviar_chutes_para_interface():\n",
    "    print(\"\\nðŸ“¤ Reenviando chutes manuais para a interface do jogo...\")\n",
    "    for palavra in list(memory.keys()):\n",
    "        _, score_checado = enviar_chute_site(palavra)  # reenviar no site e confirmar score real\n",
    "        print(f\"ðŸ” {palavra} â†’ confirmado no site com score {score_checado}\")\n",
    "\n",
    "def adicionar_chute_site(palavra):\n",
    "    print(f\"\\nðŸ“¤ Enviando chute direto: '{palavra}'\")\n",
    "    chute, score = enviar_chute_site(palavra)\n",
    "\n",
    "    if score is None:\n",
    "        print(f\"â­ï¸ Ignorado: '{chute}' nÃ£o retornou score (talvez repetido ou erro).\")\n",
    "        return\n",
    "\n",
    "    memory[chute] = score\n",
    "    get_embedding(chute)\n",
    "    print(f\"ðŸ“¥ Registrado: '{chute}' com score {score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d2927b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(5)\n",
    "def loop_automatico():\n",
    "    reenviar_chutes_para_interface()\n",
    "    while True:\n",
    "        proximas = sugerir_proximo()\n",
    "        print(proximas)\n",
    "        for i in range(len(proximas)):\n",
    "            print(f\"\\nEnviando chute: {proximas[i]}\")\n",
    "            chute, score = enviar_chute_site(proximas[i])\n",
    "            print(f\"ðŸ” chute: {chute} (score={score})\")\n",
    "        \n",
    "            if score is not None:\n",
    "                adicionar_chute(chute, score)\n",
    "            else:\n",
    "                print(\"â­ï¸ Ignorando chute invÃ¡lido ou repetido.\")\n",
    "\n",
    "            if score == 0:\n",
    "                print(\"ðŸŽ‰ Palavra secreta encontrada:\", chute)\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7bc4b93c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Iniciando jogo\n",
      "\n",
      "ðŸ“¤ Reenviando chutes manuais para a interface do jogo...\n",
      "\n",
      "ðŸŽ¯ Gerando novas sugestÃµes...\n",
      "ðŸ§­ ComeÃ§ando exploraÃ§Ã£o: family\n",
      "['family']\n",
      "\n",
      "Enviando chute: family\n",
      "\n",
      "aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa'family'\n",
      "ðŸ” chute: family (score=2182)\n",
      "Chute registrado: 'family' com score 2182\n",
      "\n",
      "ðŸŽ¯ Gerando novas sugestÃµes...\n",
      "ðŸ” Todos os chutes estÃ£o ruins. Explorando novo tema: emotion\n",
      "['emotion']\n",
      "\n",
      "Enviando chute: emotion\n",
      "\n",
      "aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa'emotion'\n",
      "ðŸ” chute: emotion (score=4132)\n",
      "Chute registrado: 'emotion' com score 4132\n",
      "\n",
      "ðŸŽ¯ Gerando novas sugestÃµes...\n",
      "ðŸ” Todos os chutes estÃ£o ruins. Explorando novo tema: profession\n",
      "['profession']\n",
      "\n",
      "Enviando chute: profession\n",
      "\n",
      "aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa'profession'\n",
      "ðŸ” chute: profession (score=1959)\n",
      "Chute registrado: 'profession' com score 1959\n",
      "\n",
      "ðŸŽ¯ Gerando novas sugestÃµes...\n",
      "ðŸ” Todos os chutes estÃ£o ruins. Explorando novo tema: animal\n",
      "['animal']\n",
      "\n",
      "Enviando chute: animal\n",
      "\n",
      "aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa'animal'\n",
      "ðŸ” chute: animal (score=3054)\n",
      "Chute registrado: 'animal' com score 3054\n",
      "\n",
      "ðŸŽ¯ Gerando novas sugestÃµes...\n",
      "ðŸ” Todos os chutes estÃ£o ruins. Explorando novo tema: food\n",
      "['food']\n",
      "\n",
      "Enviando chute: food\n",
      "\n",
      "aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa'food'\n",
      "ðŸ” chute: food (score=1810)\n",
      "Chute registrado: 'food' com score 1810\n",
      "\n",
      "ðŸŽ¯ Gerando novas sugestÃµes...\n",
      "ðŸ” Todos os chutes estÃ£o ruins. Explorando novo tema: color\n",
      "['color']\n",
      "\n",
      "Enviando chute: color\n",
      "\n",
      "aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa'color'\n",
      "ðŸ” chute: color (score=2073)\n",
      "Chute registrado: 'color' com score 2073\n",
      "\n",
      "ðŸŽ¯ Gerando novas sugestÃµes...\n",
      "ðŸ” Todos os chutes estÃ£o ruins. Explorando novo tema: music\n",
      "['music']\n",
      "\n",
      "Enviando chute: music\n",
      "\n",
      "aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa'music'\n",
      "ðŸ” chute: music (score=1254)\n",
      "Chute registrado: 'music' com score 1254\n",
      "\n",
      "ðŸŽ¯ Gerando novas sugestÃµes...\n",
      "ðŸ” Todos os chutes estÃ£o ruins. Explorando novo tema: plant\n",
      "['plant']\n",
      "\n",
      "Enviando chute: plant\n",
      "\n",
      "aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa'plant'\n",
      "ðŸ” chute: plant (score=2214)\n",
      "Chute registrado: 'plant' com score 2214\n",
      "\n",
      "ðŸŽ¯ Gerando novas sugestÃµes...\n",
      "ðŸ” Todos os chutes estÃ£o ruins. Explorando novo tema: clothing\n",
      "['clothing']\n",
      "\n",
      "Enviando chute: clothing\n",
      "\n",
      "aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa'clothing'\n",
      "ðŸ” chute: clothes (score=2126)\n",
      "Chute registrado: 'clothes' com score 2126\n",
      "\n",
      "ðŸŽ¯ Gerando novas sugestÃµes...\n",
      "ðŸ” Todos os chutes estÃ£o ruins. Explorando novo tema: technology\n",
      "['technology']\n",
      "\n",
      "Enviando chute: technology\n",
      "\n",
      "aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa'technology'\n",
      "ðŸ” chute: technology (score=72)\n",
      "Chute registrado: 'technology' com score 72\n",
      "\n",
      "ðŸŽ¯ Gerando novas sugestÃµes...\n",
      "ðŸŒŸ Refinando a partir de Ã³timos (1): ['technology']\n",
      "âœ… PrÃ³xima sugestÃ£o: None (sim=-1.0000)\n",
      "['telecommunication', 'physics', 'culinary', 'design', 'therapy', 'astronomy', 'machinery', 'dentistry', 'debate', 'topics']\n",
      "\n",
      "Enviando chute: telecommunication\n",
      "\n",
      "aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa'telecommunication'\n",
      "ðŸ” chute: telecommunication (score=3370)\n",
      "Chute registrado: 'telecommunication' com score 3370\n",
      "\n",
      "Enviando chute: physics\n",
      "\n",
      "aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa'physics'\n",
      "ðŸ” chute: physic (score=4362)\n",
      "Chute registrado: 'physic' com score 4362\n",
      "\n",
      "Enviando chute: culinary\n",
      "\n",
      "aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa'culinary'\n",
      "ðŸ” chute: culinary (score=4456)\n",
      "Chute registrado: 'culinary' com score 4456\n",
      "\n",
      "Enviando chute: design\n",
      "\n",
      "aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa'design'\n",
      "ðŸ” chute: design (score=26)\n",
      "Chute registrado: 'design' com score 26\n",
      "\n",
      "Enviando chute: therapy\n",
      "\n",
      "aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa'therapy'\n",
      "ðŸ” chute: therapy (score=1732)\n",
      "Chute registrado: 'therapy' com score 1732\n",
      "\n",
      "Enviando chute: astronomy\n",
      "\n",
      "aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa'astronomy'\n",
      "ðŸ” chute: astronomy (score=4721)\n",
      "Chute registrado: 'astronomy' com score 4721\n",
      "\n",
      "Enviando chute: machinery\n",
      "\n",
      "aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa'machinery'\n",
      "ðŸ” chute: machinery (score=215)\n",
      "Chute registrado: 'machinery' com score 215\n",
      "\n",
      "Enviando chute: dentistry\n",
      "\n",
      "aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa'dentistry'\n",
      "ðŸ” chute: dentistry (score=9208)\n",
      "Chute registrado: 'dentistry' com score 9208\n",
      "\n",
      "Enviando chute: debate\n",
      "\n",
      "aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa'debate'\n",
      "ðŸ” chute: debate (score=4761)\n",
      "Chute registrado: 'debate' com score 4761\n",
      "\n",
      "Enviando chute: topics\n",
      "\n",
      "aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa'topics'\n",
      "ðŸ” chute: topic (score=626)\n",
      "Chute registrado: 'topic' com score 626\n",
      "\n",
      "ðŸŽ¯ Gerando novas sugestÃµes...\n",
      "ðŸ’¥ Refinando a partir de perfeitos (1): ['design']\n",
      "âœ… PrÃ³xima sugestÃ£o: None (sim=-1.0000)\n",
      "['simulation', 'designed', 'managing', 'surgical', 'behavior', 'examination', 'disabilities', 'drawing', 'baton', 'detailing']\n",
      "\n",
      "Enviando chute: simulation\n",
      "\n",
      "aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa'simulation'\n",
      "ðŸ” chute: simulation (score=736)\n",
      "Chute registrado: 'simulation' com score 736\n",
      "\n",
      "Enviando chute: designed\n",
      "\n",
      "aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa'designed'\n",
      "âš ï¸ Palavra jÃ¡ testada: designed\n",
      "ðŸ” chute: designed (score=None)\n",
      "â­ï¸ Ignorando chute invÃ¡lido ou repetido.\n",
      "\n",
      "Enviando chute: managing\n",
      "\n",
      "aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa'managing'\n",
      "ðŸ” chute: manage (score=192)\n",
      "Chute registrado: 'manage' com score 192\n",
      "\n",
      "Enviando chute: surgical\n",
      "\n",
      "aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa'surgical'\n",
      "ðŸ” chute: surgical (score=1185)\n",
      "Chute registrado: 'surgical' com score 1185\n",
      "\n",
      "Enviando chute: behavior\n",
      "\n",
      "aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa'behavior'\n",
      "ðŸ” chute: behavior (score=1659)\n",
      "Chute registrado: 'behavior' com score 1659\n",
      "\n",
      "Enviando chute: examination\n",
      "\n",
      "aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa'examination'\n",
      "ðŸ” chute: examination (score=3332)\n",
      "Chute registrado: 'examination' com score 3332\n",
      "\n",
      "Enviando chute: disabilities\n",
      "\n",
      "aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa'disabilities'\n",
      "ðŸ” chute: disability (score=4114)\n",
      "Chute registrado: 'disability' com score 4114\n",
      "\n",
      "Enviando chute: drawing\n",
      "\n",
      "aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa'drawing'\n",
      "ðŸ” chute: drawing (score=363)\n",
      "Chute registrado: 'drawing' com score 363\n",
      "\n",
      "Enviando chute: baton\n",
      "\n",
      "aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa'baton'\n",
      "ðŸ” chute: baton (score=8543)\n",
      "Chute registrado: 'baton' com score 8543\n",
      "\n",
      "Enviando chute: detailing\n",
      "\n",
      "aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa'detailing'\n",
      "ðŸ” chute: detail (score=686)\n",
      "Chute registrado: 'detail' com score 686\n",
      "\n",
      "ðŸŽ¯ Gerando novas sugestÃµes...\n",
      "ðŸ’¥ Refinando a partir de perfeitos (1): ['design']\n",
      "âœ… PrÃ³xima sugestÃ£o: None (sim=-1.0000)\n",
      "['drawings', 'controls', 'lighting', 'guiding', 'product', 'investigations', 'inhibition', 'diffusion', 'cortex', 'consumer']\n",
      "\n",
      "Enviando chute: drawings\n",
      "\n",
      "aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa'drawings'\n",
      "âš ï¸ Palavra jÃ¡ testada: drawings\n",
      "ðŸ” chute: drawings (score=None)\n",
      "â­ï¸ Ignorando chute invÃ¡lido ou repetido.\n",
      "\n",
      "Enviando chute: controls\n",
      "\n",
      "aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa'controls'\n",
      "ðŸ” chute: control (score=187)\n",
      "Chute registrado: 'control' com score 187\n",
      "\n",
      "Enviando chute: lighting\n",
      "\n",
      "aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa'lighting'\n",
      "ðŸ” chute: lighting (score=2711)\n",
      "Chute registrado: 'lighting' com score 2711\n",
      "\n",
      "Enviando chute: guiding\n",
      "\n",
      "aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa'guiding'\n",
      "ðŸ” chute: guide (score=51)\n",
      "Chute registrado: 'guide' com score 51\n",
      "\n",
      "Enviando chute: product\n",
      "\n",
      "aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa'product'\n",
      "ðŸ” chute: product (score=39)\n",
      "Chute registrado: 'product' com score 39\n",
      "\n",
      "Enviando chute: investigations\n",
      "\n",
      "aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa'investigations'\n",
      "ðŸ” chute: investigation (score=2541)\n",
      "Chute registrado: 'investigation' com score 2541\n",
      "\n",
      "Enviando chute: inhibition\n",
      "\n",
      "aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa'inhibition'\n",
      "ðŸ” chute: inhibition (score=14804)\n",
      "Chute registrado: 'inhibition' com score 14804\n",
      "\n",
      "Enviando chute: diffusion\n",
      "\n",
      "aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa'diffusion'\n",
      "ðŸ” chute: diffusion (score=9564)\n",
      "Chute registrado: 'diffusion' com score 9564\n",
      "\n",
      "Enviando chute: cortex\n",
      "\n",
      "aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa'cortex'\n",
      "ðŸ” chute: cortex (score=15096)\n",
      "Chute registrado: 'cortex' com score 15096\n",
      "\n",
      "Enviando chute: consumer\n",
      "\n",
      "aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa'consumer'\n",
      "ðŸ” chute: consumer (score=782)\n",
      "Chute registrado: 'consumer' com score 782\n",
      "\n",
      "ðŸŽ¯ Gerando novas sugestÃµes...\n",
      "ðŸ’¥ Refinando a partir de perfeitos (2): ['design', 'product']\n",
      "âœ… PrÃ³xima sugestÃ£o: None (sim=-1.0000)\n",
      "['licensing', 'software', 'application', 'overhaul', 'substance', 'manufacturing', 'designers', 'styling', 'visually', 'weaving']\n",
      "\n",
      "Enviando chute: licensing\n",
      "\n",
      "aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa'licensing'\n",
      "ðŸ” chute: license (score=1146)\n",
      "Chute registrado: 'license' com score 1146\n",
      "\n",
      "Enviando chute: software\n",
      "\n",
      "aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa'software'\n",
      "ðŸ” chute: software (score=2)\n",
      "Chute registrado: 'software' com score 2\n",
      "\n",
      "Enviando chute: application\n",
      "\n",
      "aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa'application'\n",
      "ðŸ” chute: application (score=11)\n",
      "Chute registrado: 'application' com score 11\n",
      "\n",
      "Enviando chute: overhaul\n",
      "\n",
      "aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa'overhaul'\n",
      "ðŸ” chute: overhaul (score=2739)\n",
      "Chute registrado: 'overhaul' com score 2739\n",
      "\n",
      "Enviando chute: substance\n",
      "\n",
      "aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa'substance'\n",
      "ðŸ” chute: substance (score=4189)\n",
      "Chute registrado: 'substance' com score 4189\n",
      "\n",
      "Enviando chute: manufacturing\n",
      "\n",
      "aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa'manufacturing'\n",
      "ðŸ” chute: manufacture (score=361)\n",
      "Chute registrado: 'manufacture' com score 361\n",
      "\n",
      "Enviando chute: designers\n",
      "\n",
      "aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa'designers'\n",
      "ðŸ” chute: designer (score=834)\n",
      "Chute registrado: 'designer' com score 834\n",
      "\n",
      "Enviando chute: styling\n",
      "\n",
      "aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa'styling'\n",
      "ðŸ” chute: style (score=748)\n",
      "Chute registrado: 'style' com score 748\n",
      "\n",
      "Enviando chute: visually\n",
      "\n",
      "aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa'visually'\n",
      "ðŸ” chute: visually (score=1889)\n",
      "Chute registrado: 'visually' com score 1889\n",
      "\n",
      "Enviando chute: weaving\n",
      "\n",
      "aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa'weaving'\n",
      "ðŸ” chute: weaving (score=4783)\n",
      "Chute registrado: 'weaving' com score 4783\n",
      "\n",
      "ðŸŽ¯ Gerando novas sugestÃµes...\n",
      "ðŸ’¥ Refinando a partir de perfeitos (4): ['software', 'application', 'design', 'product']\n",
      "âœ… PrÃ³xima sugestÃ£o: None (sim=-1.0000)\n",
      "['aerospace', 'solution', 'simulator', 'technician', 'brands', 'designs', 'tissue', 'systemic', 'parachute', 'juice']\n",
      "\n",
      "Enviando chute: aerospace\n",
      "\n",
      "aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa'aerospace'\n",
      "ðŸ” chute: aerospace (score=3350)\n",
      "Chute registrado: 'aerospace' com score 3350\n",
      "\n",
      "Enviando chute: solution\n",
      "\n",
      "aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa'solution'\n",
      "ðŸ” chute: solution (score=95)\n",
      "Chute registrado: 'solution' com score 95\n",
      "\n",
      "Enviando chute: simulator\n",
      "\n",
      "aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa'simulator'\n",
      "ðŸ” chute: simulator (score=1612)\n",
      "Chute registrado: 'simulator' com score 1612\n",
      "\n",
      "Enviando chute: technician\n",
      "\n",
      "aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa'technician'\n",
      "ðŸ” chute: technician (score=1467)\n",
      "Chute registrado: 'technician' com score 1467\n",
      "\n",
      "Enviando chute: brands\n",
      "\n",
      "aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa'brands'\n",
      "ðŸ” chute: brand (score=642)\n",
      "Chute registrado: 'brand' com score 642\n",
      "\n",
      "Enviando chute: designs\n",
      "\n",
      "aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa'designs'\n",
      "âš ï¸ Palavra jÃ¡ testada: designs\n",
      "ðŸ” chute: designs (score=None)\n",
      "â­ï¸ Ignorando chute invÃ¡lido ou repetido.\n",
      "\n",
      "Enviando chute: tissue\n",
      "\n",
      "aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa'tissue'\n",
      "ðŸ” chute: tissue (score=3448)\n",
      "Chute registrado: 'tissue' com score 3448\n",
      "\n",
      "Enviando chute: systemic\n",
      "\n",
      "aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa'systemic'\n",
      "ðŸ” chute: systemic (score=8105)\n",
      "Chute registrado: 'systemic' com score 8105\n",
      "\n",
      "Enviando chute: parachute\n",
      "\n",
      "aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa'parachute'\n",
      "ðŸ” chute: parachute (score=14585)\n",
      "Chute registrado: 'parachute' com score 14585\n",
      "\n",
      "Enviando chute: juice\n",
      "\n",
      "aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa'juice'\n",
      "ðŸ” chute: juice (score=4625)\n",
      "Chute registrado: 'juice' com score 4625\n",
      "\n",
      "ðŸŽ¯ Gerando novas sugestÃµes...\n",
      "ðŸ’¥ Refinando a partir de perfeitos (4): ['software', 'application', 'design', 'product']\n",
      "âœ… PrÃ³xima sugestÃ£o: None (sim=-1.0000)\n",
      "['consulting', 'imaging', 'testing', 'diversified', 'graphic', 'brands', 'designs', 'silicon', 'catering', 'console']\n",
      "\n",
      "Enviando chute: consulting\n",
      "\n",
      "aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa'consulting'\n",
      "ðŸ” chute: consult (score=835)\n",
      "Chute registrado: 'consult' com score 835\n",
      "\n",
      "Enviando chute: imaging\n",
      "\n",
      "aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa'imaging'\n",
      "ðŸ” chute: imaging (score=1079)\n",
      "Chute registrado: 'imaging' com score 1079\n",
      "\n",
      "Enviando chute: testing\n",
      "\n",
      "aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa'testing'\n",
      "ðŸ” chute: testing (score=198)\n",
      "Chute registrado: 'testing' com score 198\n",
      "\n",
      "Enviando chute: diversified\n",
      "\n",
      "aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa'diversified'\n",
      "ðŸ” chute: diversify (score=5528)\n",
      "Chute registrado: 'diversify' com score 5528\n",
      "\n",
      "Enviando chute: graphic\n",
      "\n",
      "aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa'graphic'\n",
      "ðŸ” chute: graphic (score=838)\n",
      "Chute registrado: 'graphic' com score 838\n",
      "\n",
      "Enviando chute: brands\n",
      "\n",
      "aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa'brands'\n",
      "âš ï¸ Palavra jÃ¡ testada: brands\n",
      "ðŸ” chute: brands (score=None)\n",
      "â­ï¸ Ignorando chute invÃ¡lido ou repetido.\n",
      "\n",
      "Enviando chute: designs\n",
      "\n",
      "aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa'designs'\n",
      "âš ï¸ Palavra jÃ¡ testada: designs\n",
      "ðŸ” chute: designs (score=None)\n",
      "â­ï¸ Ignorando chute invÃ¡lido ou repetido.\n",
      "\n",
      "Enviando chute: silicon\n",
      "\n",
      "aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa'silicon'\n",
      "ðŸ” chute: silicon (score=4277)\n",
      "Chute registrado: 'silicon' com score 4277\n",
      "\n",
      "Enviando chute: catering\n",
      "\n",
      "aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa'catering'\n",
      "ðŸ” chute: catering (score=3936)\n",
      "Chute registrado: 'catering' com score 3936\n",
      "\n",
      "Enviando chute: console\n",
      "\n",
      "aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa'console'\n",
      "ðŸ” chute: console (score=1792)\n",
      "Chute registrado: 'console' com score 1792\n",
      "\n",
      "ðŸŽ¯ Gerando novas sugestÃµes...\n",
      "ðŸ’¥ Refinando a partir de perfeitos (4): ['software', 'application', 'design', 'product']\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[44], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mðŸ”„ Iniciando jogo\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 10\u001b[0m loop_automatico()\n",
      "Cell \u001b[1;32mIn[43], line 5\u001b[0m, in \u001b[0;36mloop_automatico\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m reenviar_chutes_para_interface()\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m----> 5\u001b[0m     proximas \u001b[38;5;241m=\u001b[39m sugerir_proximo()\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(proximas)\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(proximas)):\n",
      "Cell \u001b[1;32mIn[42], line 95\u001b[0m, in \u001b[0;36msugerir_proximo\u001b[1;34m()\u001b[0m\n\u001b[0;32m     93\u001b[0m dic_sim \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m candidatos:\n\u001b[1;32m---> 95\u001b[0m     vec \u001b[38;5;241m=\u001b[39m get_embedding(w)\n\u001b[0;32m     96\u001b[0m     sim \u001b[38;5;241m=\u001b[39m cosine_similarity([vetor_medio], [vec])[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     97\u001b[0m     dic_sim[w] \u001b[38;5;241m=\u001b[39m sim\n",
      "Cell \u001b[1;32mIn[42], line 18\u001b[0m, in \u001b[0;36mget_embedding\u001b[1;34m(word)\u001b[0m\n\u001b[0;32m     16\u001b[0m inputs \u001b[38;5;241m=\u001b[39m tokenizer(word, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m, truncation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     17\u001b[0m inputs \u001b[38;5;241m=\u001b[39m {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m inputs\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m---> 18\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs)\n\u001b[0;32m     19\u001b[0m emb \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mlast_hidden_state\u001b[38;5;241m.\u001b[39mmean(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39msqueeze()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[0;32m     20\u001b[0m embeddings[word] \u001b[38;5;241m=\u001b[39m emb\n",
      "File \u001b[1;32mc:\\Users\\Albert\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Albert\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\Albert\\anaconda3\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:1144\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1137\u001b[0m \u001b[38;5;66;03m# Prepare head mask if needed\u001b[39;00m\n\u001b[0;32m   1138\u001b[0m \u001b[38;5;66;03m# 1.0 in head_mask indicate we keep the head\u001b[39;00m\n\u001b[0;32m   1139\u001b[0m \u001b[38;5;66;03m# attention_probs has shape bsz x n_heads x N x N\u001b[39;00m\n\u001b[0;32m   1140\u001b[0m \u001b[38;5;66;03m# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]\u001b[39;00m\n\u001b[0;32m   1141\u001b[0m \u001b[38;5;66;03m# and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]\u001b[39;00m\n\u001b[0;32m   1142\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[1;32m-> 1144\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder(\n\u001b[0;32m   1145\u001b[0m     embedding_output,\n\u001b[0;32m   1146\u001b[0m     attention_mask\u001b[38;5;241m=\u001b[39mextended_attention_mask,\n\u001b[0;32m   1147\u001b[0m     head_mask\u001b[38;5;241m=\u001b[39mhead_mask,\n\u001b[0;32m   1148\u001b[0m     encoder_hidden_states\u001b[38;5;241m=\u001b[39mencoder_hidden_states,\n\u001b[0;32m   1149\u001b[0m     encoder_attention_mask\u001b[38;5;241m=\u001b[39mencoder_extended_attention_mask,\n\u001b[0;32m   1150\u001b[0m     past_key_values\u001b[38;5;241m=\u001b[39mpast_key_values,\n\u001b[0;32m   1151\u001b[0m     use_cache\u001b[38;5;241m=\u001b[39muse_cache,\n\u001b[0;32m   1152\u001b[0m     output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[0;32m   1153\u001b[0m     output_hidden_states\u001b[38;5;241m=\u001b[39moutput_hidden_states,\n\u001b[0;32m   1154\u001b[0m     return_dict\u001b[38;5;241m=\u001b[39mreturn_dict,\n\u001b[0;32m   1155\u001b[0m )\n\u001b[0;32m   1156\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1157\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Albert\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Albert\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\Albert\\anaconda3\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:695\u001b[0m, in \u001b[0;36mBertEncoder.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    684\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[0;32m    685\u001b[0m         layer_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[0;32m    686\u001b[0m         hidden_states,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    692\u001b[0m         output_attentions,\n\u001b[0;32m    693\u001b[0m     )\n\u001b[0;32m    694\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 695\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m layer_module(\n\u001b[0;32m    696\u001b[0m         hidden_states,\n\u001b[0;32m    697\u001b[0m         attention_mask,\n\u001b[0;32m    698\u001b[0m         layer_head_mask,\n\u001b[0;32m    699\u001b[0m         encoder_hidden_states,\n\u001b[0;32m    700\u001b[0m         encoder_attention_mask,\n\u001b[0;32m    701\u001b[0m         past_key_value,\n\u001b[0;32m    702\u001b[0m         output_attentions,\n\u001b[0;32m    703\u001b[0m     )\n\u001b[0;32m    705\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    706\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[1;32mc:\\Users\\Albert\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Albert\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\Albert\\anaconda3\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:627\u001b[0m, in \u001b[0;36mBertLayer.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    624\u001b[0m     cross_attn_present_key_value \u001b[38;5;241m=\u001b[39m cross_attention_outputs[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    625\u001b[0m     present_key_value \u001b[38;5;241m=\u001b[39m present_key_value \u001b[38;5;241m+\u001b[39m cross_attn_present_key_value\n\u001b[1;32m--> 627\u001b[0m layer_output \u001b[38;5;241m=\u001b[39m apply_chunking_to_forward(\n\u001b[0;32m    628\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeed_forward_chunk, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunk_size_feed_forward, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseq_len_dim, attention_output\n\u001b[0;32m    629\u001b[0m )\n\u001b[0;32m    630\u001b[0m outputs \u001b[38;5;241m=\u001b[39m (layer_output,) \u001b[38;5;241m+\u001b[39m outputs\n\u001b[0;32m    632\u001b[0m \u001b[38;5;66;03m# if decoder, return the attn key/values as the last output\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Albert\\anaconda3\\Lib\\site-packages\\transformers\\pytorch_utils.py:253\u001b[0m, in \u001b[0;36mapply_chunking_to_forward\u001b[1;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[0;32m    250\u001b[0m     \u001b[38;5;66;03m# concatenate output at same dimension\u001b[39;00m\n\u001b[0;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcat(output_chunks, dim\u001b[38;5;241m=\u001b[39mchunk_dim)\n\u001b[1;32m--> 253\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m forward_fn(\u001b[38;5;241m*\u001b[39minput_tensors)\n",
      "File \u001b[1;32mc:\\Users\\Albert\\anaconda3\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:640\u001b[0m, in \u001b[0;36mBertLayer.feed_forward_chunk\u001b[1;34m(self, attention_output)\u001b[0m\n\u001b[0;32m    638\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfeed_forward_chunk\u001b[39m(\u001b[38;5;28mself\u001b[39m, attention_output):\n\u001b[0;32m    639\u001b[0m     intermediate_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintermediate(attention_output)\n\u001b[1;32m--> 640\u001b[0m     layer_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput(intermediate_output, attention_output)\n\u001b[0;32m    641\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m layer_output\n",
      "File \u001b[1;32mc:\\Users\\Albert\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Albert\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\Albert\\anaconda3\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:552\u001b[0m, in \u001b[0;36mBertOutput.forward\u001b[1;34m(self, hidden_states, input_tensor)\u001b[0m\n\u001b[0;32m    551\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor, input_tensor: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m--> 552\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdense(hidden_states)\n\u001b[0;32m    553\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(hidden_states)\n\u001b[0;32m    554\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mLayerNorm(hidden_states \u001b[38;5;241m+\u001b[39m input_tensor)\n",
      "File \u001b[1;32mc:\\Users\\Albert\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Albert\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\Albert\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mlinear(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "listaPalavras = []\n",
    "\n",
    "if len(listaPalavras) != 0:\n",
    "    print(\"âš ï¸ Nenhuma palavra foi passada para o loop automÃ¡tico.\") \n",
    "    for palavra in listaPalavras:\n",
    "        adicionar_chute_site(palavra)\n",
    "        print(f\"ðŸ”„ Enviando chute manual: {palavra}\")\n",
    "else:\n",
    "    print(\"ðŸ”„ Iniciando jogo\")\n",
    "loop_automatico()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
